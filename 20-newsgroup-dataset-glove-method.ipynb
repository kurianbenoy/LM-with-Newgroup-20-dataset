{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Keras glove method"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport re\nimport string\nimport numpy as np\nimport pandas as pd\nimport keras\n\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import one_hot\nfrom tqdm import tqdm\nfrom keras.models import Sequential\nfrom keras.layers import Embedding,LSTM,Dense,SpatialDropout1D\nfrom keras.layers import Input\nfrom keras.initializers import Constant\nfrom sklearn.model_selection import train_test_split\nfrom keras.optimizers import Adam\nfrom keras.models import Model\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom sklearn import metrics\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stop=set(stopwords.words('english'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/20-newsgroup-dataset/train.csv')\ntest = pd.read_csv('../input/20-newsgroup-dataset/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{},"cell_type":"markdown","source":"## Data Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([train, test])\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['texts'] = df['texts'].apply(str)\ndf['texts'] = df['texts'].str.replace(\"[^a-zA-Z]\", \" \")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_URL(text):\n    url = re.compile(r'https?://\\S+|www\\.\\S+')\n    return url.sub(r'',text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_html(text):\n    html=re.compile(r'<.*?>')\n    return html.sub(r'',text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_emoji(text):\n    emoji_pattern = re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    return emoji_pattern.sub(r'', text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_punct(text):\n    table=str.maketrans('','',string.punctuation)\n    return text.translate(table)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['texts'] = df['texts'].apply(lambda x: remove_URL(x))\ndf['texts'] = df['texts'].apply(lambda x: remove_html(x))\ndf['texts'] = df['texts'].apply(lambda x: remove_emoji(x))\ndf['texts'] = df['texts'].apply(lambda x: remove_punct(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pyspellchecker","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from spellchecker import SpellChecker\n\nspell = SpellChecker()\ndef correct_spellings(text):\n    corrected_text = []\n    misspelled_words = spell.unknown(text.split())\n    for word in text.split():\n        if word in misspelled_words:\n            corrected_text.append(spell.correction(word))\n        else:\n            corrected_text.append(word)\n    return \" \".join(corrected_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# df['texts'] = df['texts'].apply(lambda x: correct_spellings(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Coding straight forward using NLP advise\n\nhttps://stackabuse.com/python-for-nlp-multi-label-text-classification-with-keras/"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df['texts'], df['label'], test_size=0.20, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, y_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer()\ntokenizer.fit_on_texts(X_train)\n\nX_train = tokenizer.texts_to_sequences(X_train)\nX_test = tokenizer.texts_to_sequences(X_test)\n\nvocab_size = len(tokenizer.word_index) + 1\nprint(f\"No of unique words is {vocab_size}\")\n\nmaxlen = 200\n\nX_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\nX_test = pad_sequences(X_test, padding='post', maxlen=maxlen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import array\nfrom numpy import asarray\nfrom numpy import zeros","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_dict = dict()\n\nwith open('../input/glove-global-vectors-for-word-representation/glove.6B.100d.txt','r') as f:\n    for line in f:\n        records=line.split()\n        word=records[0]\n        vectors=np.asarray(records[1:],'float32')\n        embedding_dict[word]=vectors\nf.close()\n\nembedding_matrix = np.zeros((vocab_size, 100))\nfor word, index in tokenizer.word_index.items():\n    embedding_vector = embedding_dict.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[index] = embedding_vector","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"deep_inputs = Input(shape=(maxlen,))\nembedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], trainable=False)(deep_inputs)\nLSTM_Layer_1 = LSTM(64)(embedding_layer)\noutput1 = Dense(1, activation='sigmoid')(LSTM_Layer_1)\n\nmodel = Model(inputs=deep_inputs, outputs=[output1])\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=model.fit(X_train,y_train,batch_size=128,epochs=5,validation_data=(X_test,y_test),verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model.evaluate(X_test, y_test, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Test Score:\", score[0])\nprint(\"Test Accuracy:\", score[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Shahuls approach"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_corpus(df):\n    corpus = []\n    for news in tqdm(df['texts']):\n        words = [word.lower() for word in word_tokenize(news) if((word.isalpha()==1) & (word not in stop))]\n        corpus.append(words)\n    return corpus\n\ncorpus=create_corpus(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_dict = {}\nwith open('../input/glove-global-vectors-for-word-representation/glove.6B.100d.txt','r') as f:\n    for line in f:\n        values=line.split()\n        word=values[0]\n        vectors=np.asarray(values[1:],'float32')\n        embedding_dict[word]=vectors\nf.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_LEN = 300\ntokenizer_obj = Tokenizer()\ntokenizer_obj.fit_on_texts(df['texts'])\nsequences=tokenizer_obj.texts_to_sequences(corpus)\n\nnews_pad=pad_sequences(sequences,maxlen=MAX_LEN,truncating='post',padding='post')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_count = tokenizer_obj.word_index\nprint(f\"no of unique words {len(word_count)}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_words = len(word_count) + 1\nembedding_matrix = np.zeros((num_words, 100))\n\nfor word, i in tqdm(word_count.items()):\n    if i > num_words:\n        continue\n    emb_vec=embedding_dict.get(word)\n    if emb_vec is not None:\n        embedding_matrix[i]=emb_vec","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Baseline models"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CategoricalTruePositives(keras.metrics.Metric):\n\n    def __init__(self, name='categorical_true_positives', **kwargs):\n      super(CategoricalTruePositives, self).__init__(name=name, **kwargs)\n      self.true_positives = self.add_weight(name='tp', initializer='zeros')\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n      y_pred = tf.reshape(tf.argmax(y_pred, axis=1), shape=(-1, 1))\n      values = tf.cast(y_true, 'int32') == tf.cast(y_pred, 'int32')\n      values = tf.cast(values, 'float32')\n      if sample_weight is not None:\n        sample_weight = tf.cast(sample_weight, 'float32')\n        values = tf.multiply(values, sample_weight)\n      self.true_positives.assign_add(tf.reduce_sum(values))\n\n    def result(self):\n      return self.true_positives\n\n    def reset_states(self):\n      # The state of the metric will be reset at the start of each epoch.\n      self.true_positives.assign(0.)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=Sequential()\n\nembedding=Embedding(num_words,100,embeddings_initializer=Constant(embedding_matrix),\n                   input_length=MAX_LEN,trainable=False)\n\nmodel.add(embedding)\nmodel.add(SpatialDropout1D(0.2))\nmodel.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\nmodel.add(Dense(1, activation='sigmoid'))\n\n\noptimzer=Adam(learning_rate=1e-5)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = news_pad[:df.shape[0]]\ntest = news_pad[df.shape[0]:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test=train_test_split(train,df['label'].values,test_size=0.15)\nprint('Shape of train',X_train.shape)\nprint(\"Shape of Validation \",X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy',optimizer=optimzer,)\nhistory=model.fit(X_train,y_train,batch_size=256,epochs=20,validation_data=(X_test,y_test),verbose=2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = test['texts']\nx_test = tokenizer_obj.texts_to_sequences(x_test)\ntesting_seq = pad_sequences(x_test,maxlen=50)\nnews_test = pad_sequences(testing_seq,maxlen=MAX_LEN,truncating='post',padding='post')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pre = test.copy()\ntest_pre.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = model.predict_classes(news_test)\ntest_pre['label'] = predict\ntest_pre.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pre['label'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pre=model.predict(test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pre\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}